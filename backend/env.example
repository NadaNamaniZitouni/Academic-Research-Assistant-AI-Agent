# LLM Configuration
LLM_PROVIDER=ollama  # Options: "ollama", "openai", "sambanova", "gemini", "local"
LLM_MODEL_NAME=mistral  # Model name (e.g., "mistral" for Ollama, "gpt-3.5-turbo" for OpenAI)

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434  # Ollama server URL

# OpenAI Configuration (if using OpenAI)
OPENAI_API_KEY=  # Your OpenAI API key

# SambaNova Configuration (if using SambaNova)
# SAMBANOVA_API_KEY=your_sambanova_api_key_here
# LLM_MODEL_NAME=Llama-4-Maverick-17B-128E-Instruct  # or "gpt-oss-120b"

# Gemini Configuration (if using Gemini)
# GOOGLE_API_KEY=your_google_api_key_here
# LLM_MODEL_NAME=gemini-2.0-flash-001

# Embedding Model
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Paths
DATA_DIR=../data
UPLOAD_DIR=../data/uploads
INDEX_DIR=../data/indices
METADATA_DIR=../data/metadata

# FAISS Index
FAISS_INDEX_PATH=../data/indices/faiss_index.idx
METADATA_STORE_PATH=../data/metadata/chunks.jsonl
DB_PATH=../data/research_assistant.db

# API Settings
API_HOST=0.0.0.0
API_PORT=8000
CORS_ORIGINS=http://localhost:5173,http://localhost:3000

